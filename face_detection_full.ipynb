{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to ESP - Use your hostname + port\n",
    "import esppy\n",
    "esp = esppy.ESP(hostname='localhost', port=9900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 ms, sys: 3.96 ms, total: 39 ms\n",
      "Wall time: 917 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import threading\n",
    "import time\n",
    "import websocket\n",
    "import json\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import base64\n",
    "import cv2\n",
    "import esppy\n",
    "\n",
    "#esp = esppy.ESP(hostname='http://localhost:9900')\n",
    "esp_project = esp.create_project('test', n_threads=10)\n",
    "esp_project.pubsub = 'manual'\n",
    "esp_project.add_continuous_query('contquery')\n",
    "\n",
    "# Window: Video Capture\n",
    "vid_capture = esp.SourceWindow(schema=('id*:int64', 'image:blob'),\n",
    "index_type='empty', insert_only=True)\n",
    "vid_capture.pubsub = True\n",
    "esp_project.windows['w_input'] = vid_capture\n",
    "\n",
    "# Window: Video Resize\n",
    "vid_capture_resize = esp.CalculateWindow(algorithm='ImageProcessing', \n",
    "                                         name='resized', \n",
    "                                         function='resize',\n",
    "                                         height=416, \n",
    "                                         width=416, \n",
    "                                         input_map=dict(imageInput='image'), \n",
    "                                         output_map=dict(imageOutput='_image_'))\n",
    "vid_capture_resize.schema_string = 'id*:int64,image:blob,_image_:blob'\n",
    "esp_project.windows['w_resize'] = vid_capture_resize\n",
    "\n",
    "# Window: Model Reader\n",
    "model_reader = esp.ModelReaderWindow()\n",
    "esp_project.windows['w_reader'] = model_reader\n",
    "\n",
    "# Window: Model Request\n",
    "model_request = esp.SourceWindow(schema=('req_id*:int64', 'req_key:string', 'req_val:string'),index_type='empty', insert_only=True)\n",
    "esp_project.windows['w_request'] = model_request\n",
    "\n",
    "# Window: Model Score\n",
    "model_score = esp.ScoreWindow()\n",
    "model_score.pubsub = True\n",
    "model_score.add_offline_model(model_type='astore')\n",
    "def score_window_fields(number_objects):\n",
    "    _field = \"id*:int64,image:blob,_image_:blob,_nObjects_:double,\"\n",
    "    for obj in range(0,number_objects):\n",
    "        _field += \"_Object\" + str(obj) + \"_:string,\"\n",
    "        _field += \"_P_Object\" + str(obj) + \"_:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_x:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_y:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_width:double,\"\n",
    "        _field += \"_Object\" + str(obj) + \"_height:double,\"\n",
    "    return _field[:-1]\n",
    "model_score.schema_string = score_window_fields(20)\n",
    "esp_project.windows['w_score'] = model_score\n",
    "\n",
    "# Connections\n",
    "vid_capture.add_target(vid_capture_resize, role='data')\n",
    "vid_capture_resize.add_target(model_score, role='data')\n",
    "model_request.add_target(model_reader, role='request')\n",
    "model_reader.add_target(model_score, role='model')\n",
    "\n",
    "# Load Project time delta\n",
    "esp.load_project(esp_project)\n",
    "\n",
    "# Publisher: Send Model -> Adapt the reference to your model file location\n",
    "# \"usegpuesp\" tells ESP to use GPU\n",
    "# \"ndevices\" tells ESP how many GPUs to use\n",
    "pub = model_request.create_publisher(blocksize=1, rate=0, pause=0, dateformat='%Y%dT%H:%M:%S.%f', opcode='insert', format='csv')\n",
    "pub.send('i,n,1,\"usegpuesp\",\"1\"\\n')\n",
    "pub.send('i,n,2,\"ndevices\",\"1\"\\n')\n",
    "pub.send('i,n,3,\"action\",\"load\"\\n')\n",
    "pub.send('i,n,4,\"type\",\"astore\"\\n')\n",
    "#pub.send('i,n,5,\"reference\",\"/data/models/Tiny-Yolov2.astore\"\\n')\n",
    "pub.send('i,n,5,\"reference\",\"/data/models/Tiny-Yolov2_face.astore\"\\n')\n",
    "pub.send('i,n,6,,\\n')\n",
    "pub.close()\n",
    "\n",
    "# Publisher: Send Video\n",
    "pub = vid_capture.create_publisher(blocksize=1, rate=0, pause=0, opcode='insert', format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publishes frames from your camera to ESP (using base64 encoding)\n",
    "class video_pub():\n",
    "    def __init__(self, pub):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.pub = pub\n",
    "        \n",
    "    def stream(self):\n",
    "        while True:\n",
    "            ret, frame = self.cap.read()\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            _, buffer = cv2.imencode('.jpg', frame)\n",
    "            encoded_string = base64.b64encode(buffer)\n",
    "            strToSend = 'i, n, ' + str(int(time.time()*100)) + ',' + encoded_string.decode() + ',' + '\\n'\n",
    "            self.pub.send(strToSend)\n",
    "            time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, change according to your ESP server\n",
    "class video_sub():\n",
    "    def __init__(self):\n",
    "        self.ws = websocket.WebSocketApp(\"ws://localhost:9900/SASESP/subscribers/test/contquery/w_score/?format=json&mode=streaming&pagesize=1&schema=true\",\n",
    "                                 on_message = self.on_message,\n",
    "                                 on_error = self.on_error,\n",
    "                                 on_close = self.on_close)\n",
    "        self.ws.on_open = self.on_open\n",
    "        self.frame = None\n",
    "        return\n",
    "        \n",
    "    def highlightImage(self, data):\n",
    "        object_list = ['Human_Face']\n",
    "        color_palette = [\n",
    "        (0,64,255), #red\n",
    "        (0,191,255), #orange\n",
    "        (0,255,255), #yellow\n",
    "        (0,255,64), #green\n",
    "        (255,255,0) #blue\n",
    "        ]\n",
    "        obj_colors = {}\n",
    "        i = 0\n",
    "        for _object in object_list:\n",
    "            obj_colors[_object] = color_palette[i]\n",
    "            i += 1\n",
    "\n",
    "        row = data['events'][0]['event']\n",
    "        numberOfObjects = data['events'][0]['event']['_nObjects_']\n",
    "        imageBufferBase64 = data['events'][0]['event']['image']['image']\n",
    "\n",
    "        nparr = np.frombuffer(base64.b64decode(imageBufferBase64), dtype=np.uint8)\n",
    "        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        image_h, image_w,_ = frame.shape\n",
    "        for i in range(0, int(float(numberOfObjects))):\n",
    "            obj = row['_Object' + str(i) + '_']\n",
    "            prob = float(row['_P_Object' + str(i) + '_'])\n",
    "            probability = \" (\" + str(round(prob * 100, 2)) + \"%)\"\n",
    "            x = float(row['_Object' + str(i) + '_x'])\n",
    "            y = float(row['_Object' + str(i) + '_y'])\n",
    "            width = float(row['_Object' + str(i) + '_width'])\n",
    "            height = float(row['_Object' + str(i) + '_height'])\n",
    "            x1 = int(image_w * (x - width / 2))\n",
    "            y1 = int(image_h * (y - height/ 2))\n",
    "            x2 = int(image_w * (x + width / 2))\n",
    "            y2 = int(image_h * (y + height/ 2))\n",
    "            if obj in obj_colors:\n",
    "                bbox_color = obj_colors[obj]\n",
    "                border_offset = 3\n",
    "                cv2.rectangle(frame,(x1,y1),(x2,y2),bbox_color,1)\n",
    "                (label_width, label_height), baseline = cv2.getTextSize(obj + probability, cv2.FONT_HERSHEY_DUPLEX, 0.4, 1)\n",
    "                cv2.rectangle(frame,(x1,y1),(x1+label_width+10,y1-label_height-border_offset-10),bbox_color,-1)\n",
    "                cv2.putText(frame, obj.lower() + probability, (x1+5, y1-border_offset-5), cv2.FONT_HERSHEY_DUPLEX, 0.4, (0, 0, 0), 1,\n",
    "                    cv2.LINE_AA)\n",
    "        return frame\n",
    "\n",
    "    def on_message(self, message):\n",
    "        data = json.loads(message)\n",
    "        self.frame = self.highlightImage(data)\n",
    "\n",
    "    def on_error(self, error):\n",
    "        None\n",
    "        #print(error)\n",
    "\n",
    "\n",
    "    def on_close(self):\n",
    "        print(\"### closed ###\")\n",
    "\n",
    "\n",
    "    def on_open(self):\n",
    "        print('open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Publisher Thread.\n",
      "Starting Subsriber Thread.\n",
      "open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:websocket:error from callback <bound method video_sub.on_message of <__main__.video_sub object at 0x7f2c51f34ad0>>: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "print('Starting Publisher Thread.')\n",
    "video_pub1 = video_pub(pub)\n",
    "video_pub1_t = threading.Thread(target=video_pub1.stream)\n",
    "video_pub1_t.daemon = True\n",
    "video_pub1_t.start()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "print('Starting Subsriber Thread.')\n",
    "video_sub1 = video_sub()\n",
    "video_sub1_t = threading.Thread(target=video_sub1.ws.run_forever)\n",
    "video_sub1_t.daemon = True\n",
    "video_sub1_t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:websocket:error from callback <bound method video_sub.on_message of <__main__.video_sub object at 0x7f2c51f34ad0>>: 'events'\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) /io/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-893de99f5ae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Display the resulting frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/highgui/src/window.cpp:376: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    frame = video_sub1.frame\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
